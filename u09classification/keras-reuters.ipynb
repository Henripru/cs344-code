{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "source": [
        "# Classifying Article Topics using Keras\n",
        "\n",
        "Topic classification is a common task for machine learning. Here, we apply deep neural networks to the well-known [Reuters dataset](https://keras.io/datasets/#reuters-newswire-topics-classification).\n",
        "\n",
        "This example is taken from [*Deep Learning with Python*](https://github.com/fchollet/deep-learning-with-python-notebooks), F. Chollet, 2018, Section 3.5. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": [
        "from keras.datasets import reuters\n",
        "(train_data, train_labels), (test_data, test_labels) \u003d reuters.load_data(num_words\u003d10000)\n",
        "word_index \u003d reuters.get_word_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "The Reuters dataset is a textual dataset of news articles written on 46 topics. The articles are lists of word indexes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "training set         \n\tcount: 8982         \n\tshape: (8982,)         \n\timage data type: object         \n\tlabel data type: int64\n testing set         \n\tcount: 2246         \n\tshape: (2246,)\n example         \n\tarticle values: [1, 4, 1378, 2025, 9, 697, 4622, 111, 8, 25, 109, 29, 3650, 11, 150, 244, 364, 33, 30, 30, 1398, 333, 6, 2, 159, 9, 1084, 363, 13, 2, 71, 9, 2, 71, 117, 4, 225, 78, 206, 10, 9, 1214, 8, 4, 270, 5, 2, 7, 748, 48, 9, 2, 7, 207, 1451, 966, 1864, 793, 97, 133, 336, 7, 4, 493, 98, 273, 104, 284, 25, 39, 338, 22, 905, 220, 3465, 644, 59, 20, 6, 119, 61, 11, 15, 58, 579, 26, 10, 67, 7, 4, 738, 98, 43, 88, 333, 722, 12, 20, 6, 19, 746, 35, 15, 10, 9, 1214, 855, 129, 783, 21, 4, 2280, 244, 364, 51, 16, 299, 452, 16, 515, 4, 99, 29, 5, 4, 364, 281, 48, 10, 9, 1214, 23, 644, 47, 20, 324, 27, 56, 2, 2, 5, 192, 510, 17, 12]         \n\tarticle words: ? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3         \n\tarticle topic: 3\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": [
        "reverse_word_index \u003d dict([(value, key) for (key, value) in word_index.items()])\n",
        "def decode_newswire(i):\n",
        "    return \u0027 \u0027.join([reverse_word_index.get(i - 3, \u0027?\u0027) for i in train_data[i]])\n",
        "\n",
        "print(\n",
        "    f\u0027training set \\\n",
        "        \\n\\tcount: {len(train_data)} \\\n",
        "        \\n\\tshape: {train_data.shape} \\\n",
        "        \\n\\timage data type: {train_data.dtype} \\\n",
        "        \\n\\tlabel data type: {train_labels.dtype}\\n\u0027,\n",
        "    f\u0027testing set \\\n",
        "        \\n\\tcount: {len(test_labels)} \\\n",
        "        \\n\\tshape: {test_data.shape}\\n\u0027,\n",
        "    f\u0027example \\\n",
        "        \\n\\tarticle values: {test_data[0]} \\\n",
        "        \\n\\tarticle words: {decode_newswire(0)} \\\n",
        "        \\n\\tarticle topic: {test_labels[0]}\u0027\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "We process the data for use in the network by one-hot encoding the articles and the labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "one-hot vectorized:           \n\tarticle: [0. 1. 1. ... 0. 0. 0.]           \n\tlabel: [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "import numpy as np\nfrom keras.utils.np_utils import to_categorical\n\ndef vectorize_sequences(sequences, dimension\u003d10000):\n    \"\"\"This function creates a multi-hot representation of each word sequence.\n    \"\"\"\n    results \u003d np.zeros((len(sequences), dimension))\n    for i, sequence in enumerate(sequences):\n        # Set results[i] to 1 for all word indexes in sequence.\n        results[i, sequence] \u003d 1.\n    return results\n\nx_train \u003d vectorize_sequences(train_data)\nx_test \u003d vectorize_sequences(test_data)\ny_train_labels \u003d to_categorical(train_labels)\ny_test_labels \u003d to_categorical(test_labels)\n\nprint(\n      f\u0027one-hot vectorized: \\\n          \\n\\tarticle: {x_train[0]} \\\n          \\n\\tlabel: {y_train_labels[0]}\u0027\n)\n\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "We also partition out a validation dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "x_val \u003d x_train[:1000]\n",
        "partial_x_train \u003d x_train[1000:]\n",
        "\n",
        "y_val \u003d y_train_labels[:1000]\n",
        "partial_y_train \u003d y_train_labels[1000:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "We now build a three-layer network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model \u003d models.Sequential()\n",
        "model.add(layers.Dense(64, activation\u003d\u0027relu\u0027, input_shape\u003d(10000,)))\n",
        "model.add(layers.Dense(64, activation\u003d\u0027relu\u0027))\n",
        "model.add(layers.Dense(46, activation\u003d\u0027softmax\u0027))\n",
        "\n",
        "model.compile(optimizer\u003d\u0027rmsprop\u0027,\n",
        "              loss\u003d\u0027categorical_crossentropy\u0027,\n",
        "              metrics\u003d[\u0027accuracy\u0027])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "We now train the model using separate training and validation datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "scrolled": false,
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 7982 samples, validate on 1000 samples\n",
            "Epoch 1/10\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 126us/step - loss: 2.6754 - acc: 0.4841 - val_loss: 1.7588 - val_acc: 0.6130\n",
            "Epoch 2/10\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 87us/step - loss: 1.4554 - acc: 0.6844 - val_loss: 1.3422 - val_acc: 0.7080\n",
            "Epoch 3/10\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 92us/step - loss: 1.0867 - acc: 0.7694 - val_loss: 1.1727 - val_acc: 0.7330\n",
            "Epoch 4/10\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 88us/step - loss: 0.8493 - acc: 0.8136 - val_loss: 1.0591 - val_acc: 0.7640\n",
            "Epoch 5/10\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 86us/step - loss: 0.6690 - acc: 0.8587 - val_loss: 0.9900 - val_acc: 0.7880\n",
            "Epoch 6/10\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 86us/step - loss: 0.5302 - acc: 0.8886 - val_loss: 0.9398 - val_acc: 0.8050\n",
            "Epoch 7/10\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 87us/step - loss: 0.4242 - acc: 0.9107 - val_loss: 0.9555 - val_acc: 0.7950\n",
            "Epoch 8/10\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 86us/step - loss: 0.3469 - acc: 0.9263 - val_loss: 0.8928 - val_acc: 0.8070\n",
            "Epoch 9/10\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 87us/step - loss: 0.2846 - acc: 0.9386 - val_loss: 0.8817 - val_acc: 0.8200\n",
            "Epoch 10/10\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 87us/step - loss: 0.2447 - acc: 0.9449 - val_loss: 0.9134 - val_acc: 0.8200\n",
            "2246/2246 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s 119us/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.9909474231893212, 0.7858414960194143]"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "history \u003d model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs\u003d10,\n",
        "                    batch_size\u003d512,\n",
        "                    validation_data\u003d(x_val, y_val))\n",
        "model.evaluate(x_test, y_test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "scrolled": false,
        "pycharm": {}
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\u003d\n",
            "text/plain": [
              "\u003cFigure size 432x288 with 1 Axes\u003e"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "loss \u003d history.history[\u0027loss\u0027]\n",
        "val_loss \u003d history.history[\u0027val_loss\u0027]\n",
        "\n",
        "epochs \u003d range(1, len(loss) + 1)\n",
        "\n",
        "plt.plot(epochs, loss, \u0027bo\u0027, label\u003d\u0027Training loss\u0027)\n",
        "plt.plot(epochs, val_loss, \u0027b\u0027, label\u003d\u0027Validation loss\u0027)\n",
        "plt.title(\u0027Training and validation loss\u0027)\n",
        "plt.xlabel(\u0027Epochs\u0027)\n",
        "plt.ylabel(\u0027Loss\u0027)\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Try larger hidden layers, which is a bit better but much slower."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 7982 samples, validate on 1000 samples\n",
            "Epoch 1/10\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 8s 990us/step - loss: 1.9848 - acc: 0.5540 - val_loss: 1.2045 - val_acc: 0.7110\n",
            "Epoch 2/10\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 7s 909us/step - loss: 0.8276 - acc: 0.8066 - val_loss: 0.8821 - val_acc: 0.8120\n",
            "Epoch 3/10\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 7s 895us/step - loss: 0.4111 - acc: 0.9053 - val_loss: 0.8498 - val_acc: 0.8120\n",
            "Epoch 4/10\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 7s 904us/step - loss: 0.2223 - acc: 0.9463 - val_loss: 0.9099 - val_acc: 0.8130\n",
            "Epoch 5/10\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 7s 934us/step - loss: 0.2890 - acc: 0.9258 - val_loss: 0.8771 - val_acc: 0.8250\n",
            "Epoch 6/10\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 8s 1ms/step - loss: 0.1420 - acc: 0.9543 - val_loss: 0.8841 - val_acc: 0.8170\n",
            "Epoch 7/10\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 8s 1ms/step - loss: 0.1279 - acc: 0.9548 - val_loss: 0.9353 - val_acc: 0.8110\n",
            "Epoch 8/10\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 7s 933us/step - loss: 0.1201 - acc: 0.9548 - val_loss: 0.9953 - val_acc: 0.8050\n",
            "Epoch 9/10\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 8s 1ms/step - loss: 0.1159 - acc: 0.9549 - val_loss: 1.0452 - val_acc: 0.8090\n",
            "Epoch 10/10\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 9s 1ms/step - loss: 0.1015 - acc: 0.9550 - val_loss: 1.1155 - val_acc: 0.8170\n",
            "2246/2246 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s 924us/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.2561717245691288, 0.7920747996968874]"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model \u003d models.Sequential()\n",
        "model.add(layers.Dense(2048, activation\u003d\u0027relu\u0027, input_shape\u003d(10000,)))\n",
        "model.add(layers.Dense(1024, activation\u003d\u0027relu\u0027))\n",
        "model.add(layers.Dense(46, activation\u003d\u0027softmax\u0027))\n",
        "\n",
        "model.compile(optimizer\u003d\u0027rmsprop\u0027,\n",
        "              loss\u003d\u0027categorical_crossentropy\u0027,\n",
        "              metrics\u003d[\u0027accuracy\u0027])\n",
        "\n",
        "model.fit(partial_x_train,\n",
        "          partial_y_train,\n",
        "          epochs\u003d10,\n",
        "          batch_size\u003d512,\n",
        "          validation_data\u003d(x_val, y_val))\n",
        "\n",
        "model.evaluate(x_test, y_test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Try a model with a smaller hidden layer, which effectively creates an information bottleneck."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "scrolled": false,
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 7982 samples, validate on 1000 samples\n",
            "Epoch 1/20\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 137us/step - loss: 3.3505 - acc: 0.2086 - val_loss: 2.9147 - val_acc: 0.4350\n",
            "Epoch 2/20\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 85us/step - loss: 2.5752 - acc: 0.5757 - val_loss: 2.3168 - val_acc: 0.6260\n",
            "Epoch 3/20\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 71us/step - loss: 1.9959 - acc: 0.6582 - val_loss: 1.8644 - val_acc: 0.6470\n",
            "Epoch 4/20\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 85us/step - loss: 1.5839 - acc: 0.6974 - val_loss: 1.5959 - val_acc: 0.6800\n",
            "Epoch 5/20\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 89us/step - loss: 1.3246 - acc: 0.7197 - val_loss: 1.4409 - val_acc: 0.6960\n",
            "Epoch 6/20\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 82us/step - loss: 1.1596 - acc: 0.7397 - val_loss: 1.3660 - val_acc: 0.7000\n",
            "Epoch 7/20\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 79us/step - loss: 1.0399 - acc: 0.7603 - val_loss: 1.3124 - val_acc: 0.7000\n",
            "Epoch 8/20\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 79us/step - loss: 0.9439 - acc: 0.7810 - val_loss: 1.2744 - val_acc: 0.7160\n",
            "Epoch 9/20\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 87us/step - loss: 0.8653 - acc: 0.7972 - val_loss: 1.2443 - val_acc: 0.7210\n",
            "Epoch 10/20\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 87us/step - loss: 0.7955 - acc: 0.8118 - val_loss: 1.2342 - val_acc: 0.7250\n",
            "Epoch 11/20\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 89us/step - loss: 0.7361 - acc: 0.8246 - val_loss: 1.2205 - val_acc: 0.7300\n",
            "Epoch 12/20\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 68us/step - loss: 0.6816 - acc: 0.8327 - val_loss: 1.2191 - val_acc: 0.7390\n",
            "Epoch 13/20\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 86us/step - loss: 0.6321 - acc: 0.8420 - val_loss: 1.2105 - val_acc: 0.7330\n",
            "Epoch 14/20\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 87us/step - loss: 0.5879 - acc: 0.8502 - val_loss: 1.2106 - val_acc: 0.7380\n",
            "Epoch 15/20\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 100us/step - loss: 0.5482 - acc: 0.8596 - val_loss: 1.2142 - val_acc: 0.7460\n",
            "Epoch 16/20\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 94us/step - loss: 0.5097 - acc: 0.8753 - val_loss: 1.2009 - val_acc: 0.7520\n",
            "Epoch 17/20\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 87us/step - loss: 0.4764 - acc: 0.8856 - val_loss: 1.2425 - val_acc: 0.7450\n",
            "Epoch 18/20\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 79us/step - loss: 0.4472 - acc: 0.8923 - val_loss: 1.2297 - val_acc: 0.7490\n",
            "Epoch 19/20\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 86us/step - loss: 0.4202 - acc: 0.8993 - val_loss: 1.2199 - val_acc: 0.7510\n",
            "Epoch 20/20\n",
            "7982/7982 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 78us/step - loss: 0.3919 - acc: 0.9044 - val_loss: 1.2503 - val_acc: 0.7540\n",
            "2246/2246 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s 120us/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.326304891761243, 0.7355298308103295]"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model \u003d models.Sequential()\n",
        "model.add(layers.Dense(64, activation\u003d\u0027relu\u0027, input_shape\u003d(10000,)))\n",
        "model.add(layers.Dense(8, activation\u003d\u0027relu\u0027))\n",
        "model.add(layers.Dense(46, activation\u003d\u0027softmax\u0027))\n",
        "\n",
        "model.compile(optimizer\u003d\u0027rmsprop\u0027,\n",
        "              loss\u003d\u0027categorical_crossentropy\u0027,\n",
        "              metrics\u003d[\u0027accuracy\u0027])\n",
        "\n",
        "model.fit(partial_x_train,\n",
        "          partial_y_train,\n",
        "          epochs\u003d20,\n",
        "          batch_size\u003d512,\n",
        "          validation_data\u003d(x_val, y_val))\n",
        "\n",
        "model.evaluate(x_test, y_test_labels)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}